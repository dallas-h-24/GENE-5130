---
title: "Bioinformatics in R WGCNA"
author: "J. Cesar Ignacio Espinoza - Cesar   "
date: "Week 05: April 21th and 23rd 2025"
output: 
  html_document: 
    highlight: espresso
    theme: cerulean
editor_options: 
  markdown: 
    wrap: 72
---

### This class will incorporate a bit of ML.

We will be performing a WGNCA, before proceeding test yourself and make
sure you understand what weighted. Gene_network and correlation mean?

## The dataset.

we will be working with the dataset " Systems biological assessment of
immunity to severe and mild COVID-19 infections"

RNAseq analysis of PBMCs in a group of 17 COVID-19 subjects and 17
healthy controls "

```{r setup}
    ### Edit this line so your notebook renders properly
    knitr::opts_knit$set(root.dir = normalizePath("C:/Users/dalla/OneDrive/Documents/GitHub/Bioinformatics in R")) 
```

We will be using the package called WGCNA, if you do not have it
install, please run this cell, once it is installed comment it!

```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("WGCNA")
```

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("impute")
BiocManager::install("preprocessCore")

```

We now load the libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE, results="hide"}
# We first need to import the important libnrary for today's class, dplyr
library(WGCNA)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
```

Load the data (Counts table and metadata from canvas site)

```{r}
### Run this chunk to import the counts table and metadata into your evironment.
counts <- read.csv('GSE152418RawCounts.csv', header = TRUE, row.names = 1)
metadata <- read.csv('GSE152418Metadata.csv', header = TRUE, row.names = 1)

```

### QC:

Here we wanna explore to see if the dataset that we have is good for
analysis We are going to use a function called goodSamplesGenes(). Use
the cell below to display the help page of this function, figure out if
you can run it, look at the vignette and identify what this function is
doing.

```{r}
?goodSamplesGenes()

```

```{r}
### It look at the boolean list, and use it to subset your dataset
gsG <- goodSamplesGenes(t(counts))
print(gsG)

 #transposition to flip the data frame

```

Subset your data so only the genes that passed the filter are kept

```{r}
#base r
subset_genes <- counts[gsG$goodGenes,]
subset_genes <- t(subset_genes)

### dplyr

#subset_samples <- gsG %>%
#  filter(goodGenes( == TRUE))
```

#### Quick lecture 5 mins

#Sidequest 20 mins:

```{r}
# Run this cell as it is, it is generatig artificial data 
set.seed(123)
group1 <- matrix(rnorm(40, mean = 0), ncol = 2)
group2 <- matrix(rnorm(40, mean = 2.5), ncol = 2)
group3 <- matrix(rnorm(40, mean = 8), ncol = 2)

#sends to dataframe
data <- rbind(group1, group2, group3)
rownames(data) <- paste0("P", 1:nrow(data))

# Plot 
df <- as.data.frame(data)
colnames(df) <- c("x", "y")
ggplot(df, aes(x, y)) + 
  geom_point() + 
  theme_minimal()
```

Lookup the hclust function and perform clustering the data, try
different distance methods and agglomeration methods.

```{r}
### Try different distances and methods
?hclust
#hclust(d, method = "complete", members = NULL)

#?dist
#dist(x, method = "euclidean", diag = FALSE, upper = FALSE, p = 2)

### Try different distances and methods

d <- dist(df, method = "manhattan", diag = FALSE, upper = FALSE, p = 2)
x <- hclust(d, method = "complete", members = NULL)

```

How do the shapes of the deprograms differ?

Which method best recovers the intuitive groupings from the 2D plot?

When might you prefer a chaining method like "single" vs. compact (the
algorithm reduces the variance within created cluster) like "ward.D2"?

```{r}
#### Run this cell as it just plots your points beased on the create clusters
cut_and_color <- function(method, k = 3) {
  hc <- hclust(d, method = method)
  clusters <- cutree(hc, k = k)
  df$cluster <- as.factor(clusters)
  ggplot(df, aes(x, y, color = cluster)) + 
    geom_point(size = 3) +
    labs(title = paste("Clusters with", method, "linkage")) +
    theme_minimal()
}
```

```{r}
### Run our custom fucntion here, try different agglomaeration methods, and distance
```

#Discuss:

How could this apply to real biological data (e.g., gene expression
clustering)?

## Back to our main topic

Perform clustering on our data **HINT!!!** Double check that columns and
rows are as the program expects them!

A good way to detect outliers is to perform hierarchical clustering of
all the samples. If you do that you should be able to see if some data
points are too far from the rest of the samples.

```{r}
#### Perform CLustering, plot it! WHich samples would you remove?
### Int you can use the base R plot function on the object resulting from clustering

d <- dist(subset_genes, method = "euclidian", diag = FALSE, upper = FALSE, p = 2)

```

```{r}
### Write your code here
x <- hclust(d, method = "complete", members = NULL)
```

Outliers are literally that samples taht are far from each other, we can
also look at that by applying dimensionality reduction, one of the most
common techniques is PCA. run the cell below to go to the help page for
PCA

```{r}
#?prcomp
#?hclust

PCA <- prcomp(subset_genes)
```

```{r}
#### REMOVE THIS 
plot(x)
```

```{r}
#Plot the scores of these first two PCS (stored in pca$x)
ggplot(
  data = PCA$x, aes(x= PC1, y =PC2)) + geom_point() +
  geom_text(label = rownames(PCA$x))
```

```{r}
#Plot the scores of these first two PCS (stored in pca$x)

```

# Filter the data to remove bad samples

**HINT** Use DPlyr

```{r}
### TO BE REMOVED
#?dplyr
subset_genes_df <- as.data.frame(t(subset_genes))

#subset <- t(subset_genes_df)
filtered_good_genes <- as.data.frame(subset_genes_df) %>%
  dplyr::select(-GSM4614995, -GSM4615000,-GSM4614993, -GSM4614985)
```

```{r}
print(subset)
```

```{r}
t(subset_genes_df)
```

```{r}
new_metadata <- as.data.frame(t(metadata))
```

```{r}
new_metadata <- new_metadata %>%
  dplyr::select(-GSM4614995, -GSM4615000,-GSM4614993, -GSM4614985)
```

```{r}
new_metadata <- t(new_metadata)
print(new_metadata)
```

```{r}
new_metadata <- as.data.frame(new_metadata) %>%
  dplyr::select(-geo_accession,-geographical.location.ch1) %>%
  dplyr::rename("state" = "disease.state.ch1",
                "severity"="severity.ch1",
                "days"= "days_post_symptom_onset.ch1", "gender"="gender.ch1")
#the function rename is already being used in another program,
  #so we specify thet it's dyplr 's rename, not from base
```

#Normalization.

The 'easiest' way will be to run DESEq2 and use the normalized counts
object from DESeq2, Look at your past notes and run it below. You have
all you need but you might need to play with the metadata file. HINT :
df[!(row.names(df) %in% row_names_df_to_remove),] \###

```{r}

### WRITE YOUR CODE HERE, ALSO RENAME THE COLUMNS OF METADATA SO IT IS EASIER TO READ, REMOVE 'DOTS' 
phenotype  <-  ### remove samples

```

```{r}
new_pheno <-  ### rename headers
```

```{r}
### RunDeseq2
library(DESeq2)
dds <- DESeqDataSetFromMatrix()
```

dds \<- DESeqDataSetFromMatrix(countData = counts, colData =
sample_info, design = \~ dexamethasone)

```{r}
### RunDeseq2
library(DESeq2)
```

```{r}
dds <- DESeqDataSetFromMatrix(countData = filtered_good_genes, 
                              colData = new_metadata,
                              design = ~ state)
```

Now remove the genes with counts \< 15 in more than 75% of samples
(31\*0.75 \~ 23) This number is coming from the WGCNA recommendations

```{r}
dds75 <- dds[(rowSums(counts(dds)) >= 23),]  ### Subset

relevel(dds75$state, ref='Healthy')
```

```{r}
dds_norm <- vst(dds75)    ### This applies the normalization without running the whole DESEQ2 function

norm_gene_exp <- ### WGCNA needs the data in a particular shape, make sure this matches it

```

```{r}

```

### Before proceeding with WGCNA, let's see if you are keeping a cookbook with R, make a vol cano plot, and a heatmap with the DSEQ data you just generated.

```{r}
deseq_ob <- DESeq(dds75)

#### Save the results to a new object
res <- results(deseq_ob, alpha = 0.05)

```

```{r}
### Print a volcano
library(EnhancedVolcano)
#ensembl ids are not helpful/informative, so we can use the library to replace with the
#   appropriate gene symbol

library("org.Hs.eg.db")
sigs.df <-  as.data.frame(res)
#force it to use select here instead of another program


```

```{r}
### Subset for a heatmap
sigs.df$symbol <- mapIds(org.Hs.eg.db, keys= rownames(sigs.df), keytype = 'ENSEMBL', column = "SYMBOL", multiVals = "first")


```

```{r}
EnhancedVolcano(sigs.df, x='log2FoldChange', y = 'padj', lab = sigs.df$symbol,
                pCutoff = 10e-16,
                FCcutoff = 3,
                col=c('blue', 'purple', 'green', 'red'),
                pointSize = 2.0)
```

```{r}
### Print your heatmap
library(ComplexHeatmap)

```

```{r}
diff.df <- as.data.frame(sigs.df)
diff.df <- diff.df %>%
  filter(padj < 0.05)
```

```{r}

```

# We can finally start with our WGNCA data analysis

First we pick up a soft threshold modify the power vector below

```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:20), 
                  networkType = "signed", 
                  verbose = 2)
```

You can acess the results with sft\$fitIndices. We are going to pick a
power that gives us the higherst R2 and the lowest mean K.

**HINT plot the data!** First plot Power vs r2

```{r}
ggplot(data = sft$fitIndices, aes(x = Power, y = SFT.R.sq)) + geom_point()
```

Then Plot Power vs mean.k

```{r}
### Follow the example above and plot meanK 
```

After you pick up a threshold we are ready to run our data analysis

While it runs take a look at the vignette
(<https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules>)
to learn about the parameters

```{r}
### Uncoment these cells if you get issues
#temp_cor <-  cor
#cor <- WGCNA::cor

norm_gene_exp[] <- sapply(norm_gene_exp, as.numeric)
### This is the mean meat and potatos function
bwm <- blockwiseModules(norm_gene_exp, 
                 maxBlockSize = 40000,
                 TOMType = "signed",
                 power = 7, 
                 mergeCutHeight = 0.2, 
                 numericLabels = FALSE, 
                 randomSeed = 1234, 
                 verbose = 2)

```

[\#](https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules)explore
the bwm object, how many modules are there? What us the largest module?
What is the smallest?

```{r}
## RUN THIS AS IS, IT WILL PLOT THE COLORS AND DENDROGRAM
## https://www.rdocumentation.org/packages/WGCNA/versions/1.72-5/topics/plotDendroAndColors
mergedColors = labels2colors(bwm$colors)
plotDendroAndColors(
  bwm$dendrograms[[1]],
  mergedColors[bwm$blockGenes[[1]]],
  "Module colors",
  dendroLabels = FALSE,
  hang = 0.03,
  addGuide = TRUE,
  guideHang = 0.05 )

```

# Now we can correlate our findings with phenotype states of patients

Take a look at the phenotype table, we want to correlate these with our
modules (groups of genes), "one-hot encoding", for example"

```         
labels <- c("A", "B", "C")

# One-hot:
A = [1 0 0]
B = [0 1 0]
C = [0 0 1]
```

```{r}
### The easiest way is just to add a new column and subset it at the end, look at the example below, work your way and modify all the relevant traits
traits <- new_pheno %>%
  mutate(disease_state_bin = ifelse(grepl('COVID', disease_state),1,0))

```

```{r}
traits <- new_pheno %>%

```

```{r}
correlations = cor()
```

```{r}
pvalues = corPvalueStudent()
```

```{r}
## Visualiza our moduels as a heatmap
library(ComplexHeatmap)
Heatmap(correlations)
```

Pick up a few modules of interest

```{r}
## Extract the genenames of a module of interest run GSEA on it. 
### HINTS: 
labels2colors(bwm$colors)
names(bwm$colors)

### The easiest ways is to load thes two into  a DF and subset from there, but you can do it anyway.
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```
